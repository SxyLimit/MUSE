

<a name="readme-top"></a>

<div align="center">  
  <img src="misc/teaser.png" alt="MUSE Logo" width="420" style="background-color:white; display:inline-block; padding:8px;">  
</div>  

# ğŸ§  MUSE: A Memory-Utilizing and Self-Evolving Agent

> **Learning on the Job: An Experience-Driven, Self-Evolving Agent for Long-Horizon Tasks**  
> ğŸ“„ [Paper on arXiv (2510.08002)](https://arxiv.org/abs/2510.08002)

---

## âœ¨ Abstract  

Large Language Models have demonstrated remarkable capabilities across diverse domains, yet significant challenges persist when deploying them as AI agents for real-world long-horizon tasks. Existing LLM agents suffer from a critical limitation: they are test-time static and cannot learn from experience, lacking the ability to accumulate knowledge and continuously improve on the job. To address this challenge, we propose MUSE, a novel agent framework that introduces an experience-driven, self-evolving system centered around a hierarchical Memory Module. MUSE organizes diverse levels of experience and leverages them to plan and execute long-horizon tasks across multiple applications. After each sub-task execution, the agent autonomously reflects on its trajectory, converting the raw trajectory into structured experience and integrating it back into the Memory Module. This mechanism enables the agent to evolve beyond its static pretrained parameters, fostering continuous learning and self-evolution. We evaluate MUSE on the long-horizon productivity benchmark TAC. It achieves new SOTA performance by a significant margin using only a lightweight Gemini-2.5 Flash model. Sufficient Experiments demonstrate that as the agent autonomously accumulates experience, it exhibits increasingly superior task completion capabilities, as well as robust continuous learning and self-evolution capabilities. Moreover, the accumulated experience from MUSE exhibits strong generalization properties, enabling zero-shot improvement on new tasks. MUSE establishes a new paradigm for AI agents capable of real-world productivity task automation.

---

## ğŸ† Benchmark Performance

MUSE ranks **#1** on [The Agent Company Benchmark Leaderboard](https://the-agent-company.com/#/leaderboard).

<div align="center">  
  <img src="misc/TAC_rank1.png" alt="TAC Rank" width="500">  
</div>  

---

## ğŸš€ Quick Start

### Step 1: Environment Setup

```bash
conda create -n MUSE python=3.12
conda activate MUSE
pip install -r requirements.txt
playwright install chromium
playwright install-deps chromium
```

### Step 2: Run Local Demo

```bash
python demo.py
```

---

## ğŸ—‚ æ ¸å¿ƒæ¨¡å—è¯´æ˜

ä¸ºä¾¿äºå¿«é€Ÿä¸Šæ‰‹ä¸äºŒæ¬¡å¼€å‘, ä¸‹è¡¨æ¢³ç†äº†ä»“åº“ä¸­å‡ ä¸ªæ ¸å¿ƒ Python æ–‡ä»¶çš„èŒè´£ä¸å…³é”®å‡½æ•°ã€‚

### `agent.py`

* **BaseAgent**ï¼šå°è£…é€šç”¨çš„æ™ºèƒ½ä½“è¿è¡Œæµç¨‹, åŒ…æ‹¬å·¥å…·åŠ è½½ (`ToolRegistry.load_tools`)ã€å†å²è®°å½•ç®¡ç† (`save_history`) ä¸ Python ä»£ç æ‰§è¡Œ (`python_interpreter`).
* **MUSE**ï¼šç»§æ‰¿è‡ª `BaseAgent`, ç»„åˆä»»åŠ¡è§„åˆ’ã€å­ä»»åŠ¡æ‰§è¡Œã€åæ€ä¸è®°å¿†æ›´æ–°çš„æ•´ä½“é—­ç¯, æ˜¯ç³»ç»Ÿçš„å…¥å£ç±»ã€‚
* **è¾…åŠ©å‡½æ•°**ï¼šä¾‹å¦‚ `create_message`ã€`safe_json_parse` ç­‰å·¥å…·æ–¹æ³•, æ”¯æ’‘è®¡åˆ’ç”Ÿæˆä¸å·¥å…·è°ƒç”¨çš„åºåˆ—åŒ–é€»è¾‘ã€‚

### `browser.py`

* **BrowserUse**ï¼šç®¡ç†æµè§ˆå™¨ä¼šè¯ `_init_browser_session`, æš´éœ²ç½‘é¡µäº¤äº’æ¥å£å¦‚ `go_to_url`ã€`click_element_by_index`ã€`extract_content_by_vision` ç­‰, ä¾›æ™ºèƒ½ä½“è°ƒç”¨ã€‚
* **flatten_axtree_to_str**ï¼šå°†æµè§ˆå™¨å¯è®¿é—®æ€§æ ‘å±•å¼€ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸², ä¾¿äºè°ƒè¯•é¡µé¢å…ƒç´ ç»“æ„ã€‚

### `memory_manager.py`

* **MemoryManager**ï¼šè¯»å–/å†™å…¥ä¸‰ç±»é•¿æœŸè®°å¿† (`_load_memory` ä¸ `_save_memory`), å¹¶åœ¨ `update_system_prompt` ä¸­å°†ç»éªŒæ³¨å…¥ç³»ç»Ÿæç¤ºè¯ã€‚
* **è½¨è¿¹ç®¡ç†å‡½æ•°**ï¼šä¾‹å¦‚ `add_traj`ã€`trim_traj`ã€`save_run_artifacts`, ç”¨äºç»´æŠ¤å¯¹è¯å†å²ä¸äº§å‡ºè¿è¡ŒæŠ¥å‘Šã€‚

### `model.py`

* **LLM**ï¼šå¯¹æ¥ OpenAI å…¼å®¹æ¥å£, è´Ÿè´£æ„é€ è¯·æ±‚ (`prepare_messages`), å‘èµ·ä¸€æ¬¡æ€§æˆ–æµå¼ç”Ÿæˆ (`async_generate`, `async_stream_generate`) å¹¶ç»Ÿè®¡ Token æ¶ˆè€— (`_accumulate_usage`).
* **image_to_base64**ï¼šè¾…åŠ©å¤šæ¨¡æ€è°ƒç”¨, å°†æˆªå›¾ç¼–ç åæ³¨å…¥æ¶ˆæ¯ä½“ã€‚

### `run.py`

* **ä»»åŠ¡å…¥å£è„šæœ¬**ï¼šè§£æå‘½ä»¤è¡Œå‚æ•° (`parse_args`), åˆå§‹åŒ– `MUSE` æ™ºèƒ½ä½“, å¹¶è´Ÿè´£è¯„æµ‹æµç¨‹çš„æ—¥å¿—è½ç›˜ã€‚

---

## ğŸ§ª Run TAC Benchmark

To evaluate MUSE on **The Agent Company Benchmark**, please follow the detailed setup in:
ğŸ‘‰ [TheAgentCompanyForMuse Repository](https://github.com/KnowledgeXLab/TheAgentCompanyForMuse)

---

## ğŸ¥ Demo Showcase

**Task 1:** *HR - Internal Tooling Slides*

<p align="center">
  <a href="https://www.youtube.com/watch?v=8pK3SP0ZG4k&feature=youtu.be">
    <img src="misc/demo1.png" alt="Watch Demo 1" width="320" style="border-radius:12px;">
  </a>
</p>

**Task 2:** *PM - Updates Plane Issue from GitLab Status*

<p align="center">
  <a href="https://www.youtube.com/watch?v=hsM0FB9uVhs&feature=youtu.be">
    <img src="misc/demo2.png" alt="Watch Demo 2" width="320" style="border-radius:12px;">
  </a>
</p>

